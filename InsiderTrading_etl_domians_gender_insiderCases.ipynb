{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InsiderTrading_etl_domians_gender_insiderCases.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1bvdrnHlJKxV3Nm4Flja8jgjwIhxG7JbO","authorship_tag":"ABX9TyM8V+c3ovgKx9D43i/rDTP9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LqpLldtFqlPz","colab_type":"text"},"source":["# ETL Extract\n","\n","1.   Extract domains/url classification\n","2.   Get the gender from the first name of the employees\n","3.   Confirmed insider cases\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mIYWdK1XpPp6","colab_type":"text"},"source":["The classification of URL was obtained from the web link\n","[link text](http://www.shallalist.de/)\n","It contains directories named after each classification, each directory has two files domains and url e.g. advertisement\n","\n","adv\n","\n","  -> domains\n","\n","  -> urls"]},{"cell_type":"code","metadata":{"id":"eT5cfVc8tyiO","colab_type":"code","colab":{}},"source":["# execute to install not base libraries\n","#pip install genderize\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGiHLcF6rkGk","colab_type":"code","colab":{}},"source":["import os    #library to join path names\n","import pandas as pd #data manipulation library using data frames\n","import glob #library to walk directory paths\n","from genderize import Genderize #library to connect to Genderize api\n","import json #library to call json files (a.k.a by UP DS master students jotason )\n","from dateutil.relativedelta import relativedelta # library to add/substract dates\n","from datetime import datetime #library for dates manipulation\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1ucEf2IskJu","colab_type":"code","colab":{}},"source":["#Global path variables\n","bl_path='./drive/My Drive/DatosInsider/BL/' # path with all directories for URL classification\n","emp_path = './drive/My Drive/DatosInsider/r4.2/LDAP/' #path with employee information\n","dwh_path ='./drive/My Drive/DatosInsider/DWH_tables/' #final repository path\n","cnf_ins_path ='./drive/My Drive/DatosInsider/answers/' #path with confirmed Insider cases"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2gvaQsT4t1t","colab_type":"code","outputId":"6db0eeec-1fd5-493e-ce56-daf8dc9c510c","executionInfo":{"status":"ok","timestamp":1585275133339,"user_tz":360,"elapsed":9854,"user":{"displayName":"Jaime Ulises Jim�nez Cardoso","photoUrl":"","userId":"16250515277039376212"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["domain_catalogue= pd.DataFrame(columns=['type','domain_url','name'])\n","listOfFiles = list()\n","for (dirpath, bl_path, filenames) in os.walk(bl_path):\n","    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n","        \n","for file in listOfFiles:\n","  typef= file.split('/')[-2]\n","  domain_url= file.split('/')[-1]\n","  if domain_url in ['domains','urls']:\n","    try:\n","      aux_df=pd.read_csv(file, header=None,delimiter='\\n',encoding='latin')\n","      aux_df.columns=['name']\n","      aux_df['type']=typef\n","      aux_df['domain_url']=domain_url\n","      aux_df= aux_df[['type','domain_url','name']]\n","      domain_catalogue=domain_catalogue.append(aux_df)\n","    except:\n","      print(file)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["./drive/My Drive/DatosInsider/BL/dynamic/urls\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gshrBeaS23Yc","colab_type":"code","colab":{}},"source":["#Finally save results into the work repository\n","domain_catalogue.to_csv(os.path.join(dwh_path, 'BL_domains.csv') , index=False)\n","del(domain_catalogue)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UphuVxjFvenh","colab_type":"text"},"source":["LDAP directory from the CERT dataset contains information from all employees. Employees first name will be extracted and then using the Genderize api gender will be infered"]},{"cell_type":"code","metadata":{"id":"czJEpqrqrVpq","colab_type":"code","colab":{}},"source":["#Get data from all the files in the Path LDAP that includes\n","# employee information\n","all_employee_files = glob.glob(emp_path + \"*.csv\")\n","list_df = []\n","for filename in all_employee_files:\n","    df = pd.read_csv(filename, index_col=None, header=0)\n","    list_df.append(df)\n","\n","employees = pd.concat(list_df, axis=0, ignore_index=True)\n","#keep only name and ID and get unique employees \n","employees= employees[['user_id', 'employee_name']]\n","employees.drop_duplicates( \"user_id\" ,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMzrzpTatdtK","colab_type":"code","colab":{}},"source":["#Using an API get the gender of the employee based on the first name\n","# Details on https://genderize.io/  https://github.com/SteelPangolin/genderize\n","\n","employees['gender']=\"\"\n","employees['gender_probability']=\"\"\n","for idx in range(len(employees)):\n","  first_name =employees.loc[idx, 'employee_name' ].split(\" \")[0]  \n","  genero=Genderize().get([first_name] )\n","  employees['gender'].iloc[idx]= genero[0]['gender']\n","  employees['gender_probability'].iloc[idx]=genero[0]['probability']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lg6dN1teuXNx","colab_type":"code","colab":{}},"source":["#Finally save results into the work repository\n","employees.to_csv(os.path.join(dwh_path, 'employee_data.csv') )\n","del(employees)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHy4qMbCwkYV","colab_type":"text"},"source":["From the CERT data set\n","\n","This is a dataset of all true positives where the Scenario column descrives the following.\n","\n","User who did not previously use removable drives or work after hours begins logging in after hours, using a removable drive, and uploading data to wikileaks.org. Leaves the organization shortly thereafter.\n","\n","User begins surfing job websites and soliciting employment from a competitor. Before leaving the company, they use a thumb drive (at markedly higher rates than their previous activity) to steal data.\n","\n","System administrator becomes disgruntled. Downloads a keylogger and uses a thumb drive to transfer it to his supervisor's machine. The next day, he uses the collected keylogs to log in as his supervisor and send out an alarming mass email, causing panic in the organization. He leaves the organization immediately.\n","\n","Thus, 1 can be coded as Leaker, 2 as Thief and 3 as Saboteur"]},{"cell_type":"code","metadata":{"id":"L0jJ9BAIwUdV","colab_type":"code","colab":{}},"source":["insider= pd.read_csv(os.path.join(cnf_ins_path,'insiders.csv')) \n","# All data points will be considred montly. Thus, data will be transformed.\n","#only get dataset of interest\n","insider=insider[insider.dataset==4.2]\n","#transform to datetime format\n","insider['start']= pd.to_datetime( insider['start'],format='%m/%d/%Y %H:%M')\n","insider['end']= pd.to_datetime( insider['end'],format='%m/%d/%Y %H:%M')\n","#get the number of months that an insider was active i.e. committed a crime\n","insider['active_periods']= insider.apply( lambda x: (x.end.year - x.start.year) * 12 + (x.end.month - x.start.month),axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltBnRPKBxyFV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7d58c1e5-bf30-4480-9463-fef6ee4cc937","executionInfo":{"status":"ok","timestamp":1585275730384,"user_tz":360,"elapsed":600,"user":{"displayName":"Jaime Ulises Jim�nez Cardoso","photoUrl":"","userId":"16250515277039376212"}}},"source":["\n","#for each period that the insider was active create a new row in a dataframe\n","insider_cols=['user','period']\n","insider_events=pd.DataFrame(columns=insider_cols)\n","for _,ins in insider.iterrows():\n","  for idx in range(0,ins.active_periods+1):\n","    new_date=ins.start +relativedelta(months=+ idx)\n","    period= new_date.strftime('%Y%m')\n","    fields=[ins.user, period]\n","    insider_events=insider_events.append(pd.Series(fields, index=insider_cols),ignore_index=True)   \n","insider_events.shape\n"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(128, 2)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"poLEMIo_yGN7","colab_type":"code","colab":{}},"source":["insider_events.to_csv(\"./drive/My Drive/DatosInsider/DWH_tables/insider_confirmed_cases.csv\")\n","del(insider_events)"],"execution_count":0,"outputs":[]}]}